from pathlib import Path
from snakemake.utils import min_version


###


min_version("8.4.8")


configfile: "config/params.yaml"


onsuccess:
    print("Workflow finished succesfuly!")
    if config["send_email"]:
        shell(
            'mail -s "Workflow finished successfuly!" ' + config["email"] + " < {log}"
        )


onerror:
    print("An error occurred!")
    if config["send_email"]:
        shell('mail -s "An error occurred!" ' + config["email"] + " < {log}")


###


def aggregate_input(wildcards):
    """
    Aggregate input files for the downstream analysis rule
    after the checkpoint has been executed.
    """
    checkpoint_output = checkpoints.find_structural_homologs.get(**wildcards).output[0]
    with open(checkpoint_output) as f:
        homologs = f.read().splitlines()
    aggregated_input = []
    aggregated_input += expand(
        "results/{pdb_id}/separate_RNA_structures/{homolog}/MFEs.txt",
        pdb_id=wildcards.pdb_id,
        homolog=homologs,
    )
    aggregated_input += expand(
        "results/{pdb_id}/consensus_RNA_structures/{homolog}/MFEs.txt",
        pdb_id=wildcards.pdb_id,
        homolog=homologs,
    )
    return aggregated_input


# Determine the PDB IDs to process
with open("resources/list.txt") as f:
    PDB_IDs = f.read().lower().splitlines()


rule all:
    input:
        expand("results/{pdb_id}/structural_alignment/alignment.txt", pdb_id=PDB_IDs),
        expand("results/{pdb_id}/downstream_analysis/.done", pdb_id=PDB_IDs),
        expand("results/{pdb_id}/blastp_results.txt", pdb_id=PDB_IDs),


checkpoint find_structural_homologs:
    input:
        "resources/dir.cla.scope.2.08-stable.tsv",
    output:
        "results/{pdb_id}/structural_homologs.txt",
    benchmark:
        Path("benchmarks/{pdb_id}/find_structural_homologs.txt").absolute()
    threads: workflow.cores
    shell:
        """
        category=$(cat {input} | grep {wildcards.pdb_id} \
            | awk '{{print $4}}' | awk '!seen[$0]++')
        rm -f {output}.temp
        for c in $category; do
            homologs=$(cat {input} | grep $c \
                | awk '{{print $2}}' | awk '!seen[$0]++')
            echo $homologs | awk '{{gsub(" ", "\\n")}} 1' >> {output}.temp
        done
        awk '!seen[$0]++' {output}.temp > {output}
        rm {output}.temp
        """


rule download_protein_sequences_and_structures:
    input:
        rules.find_structural_homologs.output,
    output:
        "results/{pdb_id}/protein_sequences/.done",
        "results/{pdb_id}/protein_structures/.done",
        sequences=directory("results/{pdb_id}/protein_sequences"),
        structures=directory("results/{pdb_id}/protein_structures"),
        combined_sequences="results/{pdb_id}/protein_sequences/combined.fasta",
    benchmark:
        Path(
            "benchmarks/{pdb_id}/download_protein_sequences_and_structures.txt"
        ).absolute()
    threads: workflow.cores
    shell:
        """
        for e in $(cat {input}); do
            wget https://www.rcsb.org/fasta/entry/$e -q \
            -O {output.sequences}/$e.fasta
            wget https://files.rcsb.org/download/$e.pdb -q \
            -O {output.structures}/$e.pdb
        done
        cat {output.sequences}/*.fasta > {output.combined_sequences}
        touch {output.sequences}/.done
        touch {output.structures}/.done
        """


checkpoint blastp_main_protein_sequence:
    input:
        rules.download_protein_sequences_and_structures.output.sequences
        + "/{pdb_id}.fasta",
    output:
        "results/{pdb_id}/blastp_results.txt",
    log:
        Path("logs/{pdb_id}/blastp_main_protein_sequence.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/blastp_main_protein_sequence.log").absolute()
    params:
        db=config["blastp"]["database"],
        matrix=config["blastp"]["matrix"],
        evalue=config["blastp"]["e_value"],
        word_size=config["blastp"]["word_size"],
        max_target_seqs=config["blastp"]["max_target_seqs"],
        additional_args=config["blastp"]["additional_args"],
    singularity:
        "docker://ncbi/blast:2.15.0"
    threads: workflow.cores
    shell:
        """
        BLASTDB=$(pwd)/database/{params.db}:$BLASTDB

        blastp \
            -query {input} \
            -out {output} \
            -num_threads {threads} \
            -db {params.db} \
            -outfmt 6 \
            -matrix {params.matrix} \
            -evalue {params.evalue} \
            -word_size {params.word_size} \
            -max_target_seqs {params.max_target_seqs} \
            {params.additional_args} \
            &> {log}
        """


rule filter_protein_sequences:
    """
    Remove non-protein sequences from the combined file.
    """
    input:
        rules.download_protein_sequences_and_structures.output.combined_sequences,
    output:
        "results/{pdb_id}/protein_sequences/filtered_combined.fasta",
    benchmark:
        Path("benchmarks/{pdb_id}/filtered_protein_sequences.txt").absolute()
    conda:
        "envs/biopython.yaml"
    threads: workflow.cores
    script:
        "scripts/filter_protein_sequences.py"


rule align_protein_structures:
    input:
        homologs=rules.find_structural_homologs.output,
        dir=rules.download_protein_sequences_and_structures.output.structures,
    output:
        "results/{pdb_id}/structural_alignment/.done",
        alignment="results/{pdb_id}/structural_alignment/alignment.txt",
        dir=directory("results/{pdb_id}/structural_alignment/"),
    log:
        Path("logs/{pdb_id}/align_protein_structures.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/structural_alignment.txt").absolute()
    params:
        split=config["USalign"]["split"],
        full=config["USalign"]["full"],
    singularity:
        "docker://f1lem0n/usalign:latest"
    threads: workflow.cores
    shell:
        """
        # Run USalign
        USalign -dir {input.dir} {input.homologs} \
            -suffix .pdb -mm 4 -full {params.full} -o {output.dir}/sup \
            -split {params.split} > {output.dir}/alignment.txt 2> {log}

        # Remove non-ATOM lines from superposed PDB files
        for s in $(find {output.dir} -name "sup*.pdb"); do
            awk '{{if($1=="ATOM") print $0}}' $s > $s.atoms
            rm $s
            mv $s.atoms $s
        done

        # Clean up and create .done file
        rm -f *.pml
        rm -f .pdb
        touch {output.dir}/.done
        """


rule tblastn_protein_sequences:
    input:
        rules.filter_protein_sequences.output,
    output:
        "results/{pdb_id}/tblastn_results.txt",
    log:
        Path("logs/{pdb_id}/tblastn_protein_sequences.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/tblastn_protein_sequences.txt").absolute()
    params:
        db=config["tblastn"]["database"],
        matrix=config["tblastn"]["matrix"],
        evalue=config["tblastn"]["e_value"],
        word_size=config["tblastn"]["word_size"],
        max_target_seqs=config["tblastn"]["max_target_seqs"],
        additional_args=config["tblastn"]["additional_args"],
    singularity:
        "docker://ncbi/blast:2.15.0"
    threads: workflow.cores
    shell:
        """
        BLASTDB=$(pwd)/database/{params.db}:$BLASTDB

        tblastn \
            -query {input} \
            -out {output} \
            -num_threads {threads} \
            -db {params.db} \
            -outfmt 6 \
            -matrix {params.matrix} \
            -evalue {params.evalue} \
            -word_size {params.word_size} \
            -max_target_seqs {params.max_target_seqs} \
            {params.additional_args} \
            &> {log}
        """


rule download_nucleotide_sequences:
    input:
        rules.tblastn_protein_sequences.output,
    output:
        dir=directory("results/{pdb_id}/nucleotide_sequences/{homolog}"),
        combined_sequences="results/{pdb_id}/nucleotide_sequences/{homolog}/combined.fasta",
    log:
        Path("logs/{pdb_id}/download_nucleotide_sequences_{homolog}.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/nucleotide_sequences_{homolog}.txt").absolute()
    conda:
        "envs/biopython.yaml"
    threads: workflow.cores
    script:
        "scripts/download_nucleotide_sequences.py"


rule align_nucleotide_sequences:
    input:
        rules.download_nucleotide_sequences.output.combined_sequences,
    output:
        alignment="results/{pdb_id}/nucleotide_alignments/{homolog}/alignment.txt",
        dir=directory("results/{pdb_id}/nucleotide_alignments/{homolog}"),
    log:
        Path("logs/{pdb_id}/align_nucleotide_sequences_{homolog}.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/nucleotide_alignments_{homolog}.txt").absolute()
    singularity:
        "docker://biocontainers/clustalw:v2.1lgpl-6-deb_cv1"
    threads: workflow.cores
    shell:
        """
        clustalw \
            -INFILE={input} \
            -OUTFILE={output.alignment} \
            &> {log} || touch {output.alignment}
        """


rule predict_separate_RNA_structures:
    input:
        rules.download_nucleotide_sequences.output.dir,
    output:
        "results/{pdb_id}/separate_RNA_structures/{homolog}/.done",
        mfe="results/{pdb_id}/separate_RNA_structures/{homolog}/MFEs.txt",
        dir=directory("results/{pdb_id}/separate_RNA_structures/{homolog}"),
    log:
        Path("logs/{pdb_id}/predict_separate_RNA_structures_{homolog}.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/separate_RNA_structures_{homolog}.txt").absolute()
    params:
        args_string=config["RNAfold"],
        dpi=config["plots"]["DPI"],
        mountain_script=Path("workflow/scripts/mountain.pl").absolute(),
        relplot_script=Path("workflow/scripts/relplot.pl").absolute(),
    conda:
        "envs/viennaRNA.yaml"
    threads: workflow.cores
    shell:
        """
        input=$(pwd)/{input}
        cd {output.dir}
        for f in $(ls $input/*.fasta 2> {log}); do
            RNAfold \
                {params.args_string} \
                -i $f -o \
                2>> {log}
        done
        mkdir -p structures && \
        mkdir -p dotplots && \
        for f in $(ls *_dp.ps 2>> {log}); do
            sample=$(basename --suffix="_dp.ps" $f)
            perl {params.relplot_script} $sample"_ss.ps" $sample"_dp.ps" > $sample"_css".ps
            perl {params.mountain_script} $sample"_dp.ps" > $sample".mount"
            gs -dNOPAUSE -dBATCH -sDEVICE=png16m -r{params.dpi} \
                -sOutputFile=dotplots/$sample"_dp".png $sample"_dp.ps" &>> {log}
            gs -dNOPAUSE -dBATCH -sDEVICE=png16m -r{params.dpi} \
                -sOutputFile=structures/$sample"_css".png $sample"_css.ps" &>> {log}
        done && cat *.fold > MFEs.txt 2>> {log} || touch MFEs.txt
        touch .done
        cd - &>> {log}
        """


rule predict_consensus_RNA_structure:
    input:
        rules.align_nucleotide_sequences.output.alignment,
    output:
        "results/{pdb_id}/consensus_RNA_structures/{homolog}/MFEs.txt",
        dir=directory("results/{pdb_id}/consensus_RNA_structures/{homolog}"),
    log:
        Path("logs/{pdb_id}/predict_consensus_RNA_structure_{homolog}.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/consensus_RNA_structures_{homolog}.txt").absolute()
    params:
        args_string=config["RNAalifold"],
        dpi=config["plots"]["DPI"],
        mountain_script=Path("workflow/scripts/cmount.pl").absolute(),
    conda:
        "envs/viennaRNA.yaml"
    threads: workflow.cores
    shell:
        """
        input=$(pwd)/{input}
        cd {output.dir}
        RNAalifold \
            {params.args_string} \
            < $input > MFEs.txt 2> {log} \
        && perl {params.mountain_script} alidot.ps > mountain.ps \
        && gs -dNOPAUSE -dBATCH -sDEVICE=png16m -r{params.dpi} \
            -sOutputFile=alidot.png alidot.ps &>> {log} \
        && gs -dNOPAUSE -dBATCH -sDEVICE=png16m -r{params.dpi} \
            -sOutputFile=alirna.png alirna.ps &>> {log} \
        && gs -dNOPAUSE -dBATCH -sDEVICE=png16m -r{params.dpi} \
            -sOutputFile=mountain.png mountain.ps &>> {log} \
        || touch MFEs.txt
        cd - &>> {log}
        """


rule downstream_analysis:
    input:
        rules.tblastn_protein_sequences.output,
        aggregate_input,
    output:
        "results/{pdb_id}/downstream_analysis/.done",
        dir=directory("results/{pdb_id}/downstream_analysis/"),
    log:
        Path("logs/{pdb_id}/downstream_analysis.log").absolute(),
    benchmark:
        Path("benchmarks/{pdb_id}/downstream_analysis.txt").absolute()
    conda:
        "envs/dplyr.yaml"
    threads: workflow.cores
    script:
        "scripts/downstream_analysis.R"
